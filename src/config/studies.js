/**
 * Configura√ß√£o de Estudos - Estrutura Hier√°rquica
 * @description Forma√ß√µes > Cursos > Labs/Projetos
 */

/**
 * Lista de Forma√ß√µes (N√≠vel Superior)
 * Adicione novas forma√ß√µes aqui
 */
export const FORMATIONS = [
    {
        id: 'engenharia-dados-4',
        name: 'Engenharia de Dados 4.0',
        fullName: 'Forma√ß√£o Engenharia de Dados 4.0 - Data Science Academy',
        icon: 'üéì',
        color: '#00D4AA',
        institution: 'Data Science Academy',
        description: 'Onde minha transi√ß√£o ganhou forma. Mergulhei em Python, SQL e conceitos de estat√≠stica ‚Äî fundamentos essenciais para qualquer engenheiro de dados. A cada m√≥dulo, constru√≠ projetos que transformaram teoria em pr√°tica.'
    },
    {
        id: 'fullstack-data-pod',
        name: 'Full Stack Data & Analytics',
        fullName: 'Forma√ß√£o Full Stack Data & Analytics - Pod Academy (550h)',
        icon: 'üìä',
        color: '#FF6B35',
        institution: 'Pod Academy',
        description: 'Programa avan√ßado de 550 horas que re√∫ne disciplinas completas de Engenharia de Dados, An√°lise de Dados, Ci√™ncia de Dados e Cloud Computing. Projeto Pr√°tico de Conclus√£o aprovado por banca de executivos.',
        subFormations: [
            { id: 'analise-dados', name: 'Forma√ß√£o An√°lise de Dados', icon: 'üìà' },
            { id: 'ciencia-dados', name: 'Forma√ß√£o Ci√™ncia de Dados', icon: 'üî¨' },
            { id: 'engenharia-dados', name: 'Forma√ß√£o Engenharia de Dados', icon: '‚öôÔ∏è' },
        ]
    },
    {
        id: 'formacoes-alura',
        name: 'Forma√ß√µes Alura',
        fullName: 'Forma√ß√µes em Dados - Alura',
        icon: 'üîµ',
        color: '#0066FF',
        institution: 'Alura',
        description: 'Forma√ß√µes especializadas em tecnologias de dados: Analytics, AWS Data Lake, Apache Airflow e DataMesh. Aprofundamento cont√≠nuo em ferramentas e arquiteturas modernas.',
        subFormations: [
            { id: 'eng-analytics', name: 'Forma√ß√£o Engenharia de Analytics', icon: 'üìä' },
            { id: 'aws-data-lake', name: 'Forma√ß√£o AWS Data Lake: pipelines na AWS', icon: '‚òÅÔ∏è' },
            { id: 'apache-airflow', name: 'Forma√ß√£o Apache Airflow', icon: 'üåä' },
            { id: 'data-mesh', name: 'Forma√ß√£o Data Mesh', icon: 'üîó' },
        ]
    },
    {
        id: 'engenharia-software-dados',
        name: 'Eng. de Software para Dados',
        fullName: 'Engenharia de Software para Dados - Apoena Stack',
        icon: 'üìö',
        color: '#8B5CF6',
        institution: 'Apoena Stack',
        description: 'Especializa√ß√£o focada em arquitetura de dados, algoritmos eficientes e orquestra√ß√£o de pipelines. Mentoria do instrutor Iury com √™nfase em qualidade de c√≥digo e performance.'
    }
];

/**
 * Lista de Cursos organizados por Forma√ß√£o
 */
export const COURSES = [
    // ========================================
    // FORMA√á√ÉO: Engenharia de Dados 4.0 - DSA
    // ========================================
    {
        id: 'iac-terraform',
        name: 'Infraestrutura e Cloud',
        fullName: 'Infraestrutura como C√≥digo e Cloud (Terraform, AWS, Azure, Databricks)',
        icon: 'üèóÔ∏è',
        color: '#7B42BC', // Terraform purple
        formation: 'engenharia-dados-4',
        description: 'Neste conjunto de atividades, o objetivo foi aprender a provisionar e gerenciar recursos na nuvem de forma automatizada usando Infraestrutura como C√≥digo. As tecnologias centrais incluem Terraform (para defini√ß√£o de infraestrutura), AWS (servi√ßos como EC2, EMR e S3), Microsoft Azure e Databricks. Nos projetos pr√°ticos, utilizei esses recursos para criar ambientes de processamento de dados escal√°veis.'
    },
    {
        id: 'airbyte-dbt',
        name: 'ETL/ELT com Airbyte e DBT',
        fullName: 'ETL/ELT com Airbyte e DBT',
        icon: 'üîÑ',
        color: '#FF6B35', // DBT Orange
        formation: 'engenharia-dados-4',
        description: 'A pr√≥xima fase focou na integra√ß√£o e transforma√ß√£o de dados. Usei o Airbyte como plataforma de ETL/ELT para extrair dados de diferentes fontes e carreg√°-los em bancos de dados de destino. Paralelamente, utilizei o DBT para modelagem de dados e constru√ß√£o de transforma√ß√µes SQL.'
    },
    {
        id: 'data-warehouse',
        name: 'Data Warehousing e SQL',
        fullName: 'Modelagem, Implementa√ß√£o e Governan√ßa de Data Warehouses',
        icon: 'üè¢',
        color: '#4285F4', // Google Blue
        formation: 'engenharia-dados-4',
        description: 'Essa etapa concentrou-se em modelagem, implementa√ß√£o e consulta em Data Warehouses. Trabalhei com bancos de dados para an√°lises, usando Amazon Redshift e Amazon Athena no AWS, al√©m de ferramentas tradicionais como PostgreSQL. Os projetos envolveram defini√ß√£o de esquemas, otimiza√ß√£o de consultas SQL e migra√ß√£o de dados.'
    },
    {
        id: 'pipelines-airflow',
        name: 'Data Lake e Lakehouse',
        fullName: 'Armazenamento e Gest√£o de Dados com Data Lake e Data Lakehouse',
        icon: 'üåä',
        color: '#00D4AA', // Airflow Green-ish
        formation: 'engenharia-dados-4',
        description: 'Transforme dados em insights com Data Lakes e Data Lakehouses.'
    },
    {
        id: 'pyspark-kafka',
        name: 'Big Data com PySpark e Kafka',
        fullName: 'Big Data e Processamento com PySpark e Kafka',
        icon: '‚ö°',
        color: '#E25A1C', // Spark Orange
        formation: 'engenharia-dados-4',
        description: 'Por fim, aprofundei-me em processamento de dados em larga escala, usando PySpark para tarefas batch/streaming e Apache Kafka para ingest√£o de eventos em tempo real. Os projetos pr√°ticos abordaram desde a manipula√ß√£o de arquivos distribu√≠dos at√© streaming em tempo real.'
    }
    // Adicione cursos de outras forma√ß√µes aqui
];

/**
 * Helper: Obter cursos de uma forma√ß√£o espec√≠fica
 */
export const getCoursesByFormation = (formationId) => {
    return COURSES.filter(course => course.formation === formationId);
};

/**
 * Categorias para filtro
 */
export const STUDY_CATEGORIES = [
    'Todos',
    ...COURSES.map(c => c.name)
];

/**
 * Configura√ß√£o da p√°gina de Estudos
 */
export const studiesPageConfig = {
    title: "Estudos",
    subtitle: "Da Ind√∫stria √† Engenharia de Dados",
    description: "Minha trajet√≥ria come√ßou na √°rea industrial, mas logo percebi o crescente impacto dos dados na tomada de decis√£o e na otimiza√ß√£o de processos. A transi√ß√£o para Engenharia de Dados foi motivada pela curiosidade em entender como coletar, processar e analisar grandes volumes de informa√ß√£o. Para isso, participei de cursos focados em pr√°tica hands-on, construindo projetos que envolvem desde a configura√ß√£o de infraestrutura na nuvem at√© a implementa√ß√£o de pipelines e modelagem de dados. Cada etapa da minha jornada incorporou aplica√ß√µes concretas de tecnologias relevantes, consolidando conhecimento por meio de laborat√≥rios e reposit√≥rios de c√≥digo.",
    institutionsLabel: "Institui√ß√µes onde estudei",
    // Detalhes por institui√ß√£o
    institutionDetails: {
        "Data Science Academy": "Forma√ß√£o em Analista/Engenheiro de Dados 4.0 ‚Äî cursos de Python, SQL, Machine Learning e Estat√≠stica. Base s√≥lida em melhores pr√°ticas de programa√ß√£o e an√°lise de dados.",
        "Pod Academy": "Bootcamp Full Stack Dados & Analytics ‚Äî Engenharia de Dados, Cloud (AWS/GCP), Data Science e projetos hands-on. Hackathons e squads multidisciplinares.",
        "Alura": "Certifica√ß√µes em Data Science e Cloud Computing ‚Äî m√≥dulos sobre SQL, Python avan√ßado, AWS, BigQuery e tecnologias emergentes.",
        "Apoena Stack": "Especializa√ß√£o em Engenharia de Software para Dados ‚Äî √™nfase em pipelines, testes automatizados, boas pr√°ticas de codifica√ß√£o e arquitetura de dados."
    },
    // Lista de institui√ß√µes onde estudo
    institutions: [
        { name: "Data Science Academy", icon: "üéì" },
        { name: "Pod Academy", icon: "üìä" },
        { name: "Alura", icon: "üîµ" },
        { name: "Apoena Stack", icon: "üìö" },
    ]
};

/**
 * Lista completa de Estudos organizados por curso
 */
export const studies = [
    // ========================================
    // CURSO 1: Infraestrutura e Cloud
    // ========================================
    {
        id: 101,
        title: "Estudo de Caso - Deploy de App com Docker e Agente de IA Para Provisionamento de Infraestrutura com IaC",
        type: "Estudo de Caso",
        description: "Deploy de aplica√ß√£o containerizada com Docker e uso de Agente de IA para automatizar o provisionamento de infraestrutura utilizando Infrastructure as Code.",
        technologies: ["Docker", "Terraform", "IA", "IaC"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_estudo_caso.png`,
        github: "https://github.com/tmarsbr/estudo-caso-docker-ia-iac",
        date: "2024"
    },
    {
        id: 102,
        title: "Lab 1 - Automatizando a Infraestrutura de Inst√¢ncias EC2 na Nuvem AWS com Terraform",
        type: "Laborat√≥rio",
        description: "Automa√ß√£o de provisionamento de inst√¢ncias EC2 na AWS utilizando Terraform para Infrastructure as Code. Container Docker com ambiente completo para IaC.",
        technologies: ["Terraform", "AWS", "EC2", "IaC", "Docker"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_lab1.png`,
        github: "https://github.com/tmarsbr/Lab_1_projeto_automatizando_a_infraestrutura",
        date: "2024"
    },
    {
        id: 103,
        title: "Lab 2 - Automatizando a Infraestrutura na Nuvem AWS com Vari√°veis no Terraform",
        type: "Laborat√≥rio",
        description: "Uso avan√ßado de vari√°veis no Terraform para criar infraestrutura flex√≠vel e reutiliz√°vel na AWS.",
        technologies: ["Terraform", "AWS", "Vari√°veis", "IaC"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_lab2.png`,
        github: "https://github.com/tmarsbr/Lab-2-IaC-Stack-Variaveis-Terraform",
        date: "2024"
    },
    {
        id: 104,
        title: "Lab 3 - Usando Terraform Provisioners e Outras Tarefas de Automa√ß√£o",
        type: "Laborat√≥rio",
        description: "Explora√ß√£o de Terraform Provisioners para executar scripts e comandos durante o provisionamento de recursos.",
        technologies: ["Terraform", "Provisioners", "AWS", "Automa√ß√£o"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_lab3.png`,
        github: "https://github.com/tmarsbr/Lab-3-IaC-Stack-Terraform-Provisioners",
        date: "2024"
    },
    {
        id: 105,
        title: "Lab 4 - Deploy de Infraestrutura e API Para Aplica√ß√£o de Data Science na AWS com Terraform",
        type: "Laborat√≥rio",
        description: "Deploy completo de infraestrutura e API REST para aplica√ß√µes de Data Science na AWS utilizando Terraform.",
        technologies: ["Terraform", "AWS", "API", "Data Science"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_lab4.png`,
        github: "https://github.com/tmarsbr/Lab-4-IaC-AWS-Infra-API-Data-Science",
        date: "2024"
    },
    {
        id: 106,
        title: "Lab 5 - IaC com Terraform Para Deploy de Aplica√ß√£o Web em Container Docker no AWS ECS",
        type: "Laborat√≥rio",
        description: "Deploy de aplica√ß√£o web containerizada no AWS ECS (Elastic Container Service) utilizando Terraform.",
        technologies: ["Terraform", "AWS ECS", "Docker", "IaC"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_lab5.png`,
        github: "https://github.com/tmarsbr/Lab-5-IaC-AWS-ECS-Docker-WebApp",
        date: "2024"
    },
    {
        id: 107,
        title: "Projeto 1 - Automatizando Infraestrutura de Processamento de Dados com AWS EMR e Apache Flink",
        type: "Projeto",
        description: "Automa√ß√£o de cluster AWS EMR com Apache Flink para processamento de dados em larga escala.",
        technologies: ["Terraform", "AWS EMR", "Apache Flink", "Big Data"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_projeto1.png`,
        github: "https://github.com/tmarsbr/aws-emr-flink-portfolio",
        date: "2024"
    },
    {
        id: 108,
        title: "Projeto 2 - Deploy do Stack de Treinamento Distribu√≠do de ML com PySpark no Amazon EMR",
        type: "Projeto",
        description: "Deploy de infraestrutura para treinamento distribu√≠do de modelos de Machine Learning utilizando PySpark no Amazon EMR.",
        technologies: ["Terraform", "AWS EMR", "PySpark", "Machine Learning"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_projeto2.png`,
        github: "https://github.com/tmarsbr/Projeto-2-AWS-EMR-PySpark-ML",
        date: "2024"
    },
    {
        id: 109,
        title: "Projeto 3 - Deploy do Stack de Infraestrutura de Dados no Azure com Terraform",
        type: "Projeto",
        description: "Provisionamento de infraestrutura de dados completa no Microsoft Azure utilizando Terraform.",
        technologies: ["Terraform", "Azure", "Data Engineering", "IaC"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_projeto3.png`,
        github: "https://github.com/tmarsbr/Projeto-3-Azure-Terraform-Data-Infra",
        date: "2024"
    },
    {
        id: 110,
        title: "Projeto 4 - AWS e Azure Multi-Cloud Deploy com Terraform",
        type: "Projeto",
        description: "Deploy multi-cloud combinando recursos da AWS e Azure em uma √∫nica configura√ß√£o Terraform.",
        technologies: ["Terraform", "AWS", "Azure", "Multi-Cloud"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_projeto4.png`,
        github: "https://github.com/tmarsbr/Projeto-4-Multi-Cloud-AWS-Azure-Terraform",
        date: "2024"
    },
    {
        id: 111,
        title: "Projeto 5 - Databricks Cluster Deploy com Terraform Para Processamento Distribu√≠do",
        type: "Projeto",
        description: "Deploy automatizado de cluster Databricks com Terraform para processamento de dados distribu√≠do.",
        technologies: ["Terraform", "Databricks", "Spark", "Data Engineering"],
        course: "iac-terraform",
        courseName: "Infraestrutura e Cloud",
        image: `${process.env.PUBLIC_URL}/projects/iac_projeto5.png`,
        github: "https://github.com/tmarsbr/projeto5-databricks-terraform",
        date: "2024"
    },

    // ========================================
    // CURSO 2: Data Warehouses e SQL
    // ========================================
    {
        id: 201,
        title: "Lab 1 - Automa√ß√£o da Infraestrutura de Consultas SQL com Terraform e BigQuery no GCP",
        type: "Laborat√≥rio",
        description: "Automa√ß√£o de infraestrutura de consultas SQL utilizando Terraform e BigQuery no Google Cloud Platform.",
        technologies: ["Terraform", "BigQuery", "GCP", "SQL"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_lab1.png`,
        github: "https://github.com/tmarsbr/DWH-Lab-1-GCP-BigQuery-Terraform",
        date: "2024"
    },
    {
        id: 202,
        title: "Lab 2 - Usando o ChatGPT Para Construir Um Modelo Dimensional de Forma Segura",
        type: "Laborat√≥rio",
        description: "Utiliza√ß√£o de IA generativa (ChatGPT) como ferramenta auxiliar para constru√ß√£o de modelos dimensionais seguindo boas pr√°ticas.",
        technologies: ["ChatGPT", "Modelagem Dimensional", "Data Warehouse", "IA"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_lab2.png`,
        github: "https://github.com/tmarsbr/DWH-Lab-2-ChatGPT-Modelo-Dimensional-Seguro",
        date: "2024"
    },
    {
        id: 203,
        title: "Lab 3 - Airbyte e SQL Para ETL no Data Warehouse em Ambiente Local",
        type: "Laborat√≥rio",
        description: "Implementa√ß√£o de pipeline ETL utilizando Airbyte e SQL em ambiente local de Data Warehouse.",
        technologies: ["Airbyte", "SQL", "ETL", "Docker"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_lab3.png`,
        github: "https://github.com/tmarsbr/DWH-Lab-3-Airbyte-SQL-ETL-Local",
        date: "2024"
    },
    {
        id: 204,
        title: "Lab 4 - Processo de Governan√ßa e Qualidade de Dados no Data Warehouse",
        type: "Laborat√≥rio",
        description: "Implementa√ß√£o de processos de governan√ßa e qualidade de dados em ambiente de Data Warehouse.",
        technologies: ["Governan√ßa", "Qualidade de Dados", "Data Warehouse", "SQL"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_lab4.png`,
        github: "https://github.com/tmarsbr/DWH-Lab-4-Governanca-Qualidade-Dados-DWH",
        date: "2024"
    },
    {
        id: 205,
        title: "Lab 5 - Migra√ß√£o de Data Warehouse Local Para a Nuvem",
        type: "Laborat√≥rio",
        description: "Processo completo de migra√ß√£o de Data Warehouse de ambiente local para infraestrutura em nuvem.",
        technologies: ["Migra√ß√£o", "Cloud", "Data Warehouse", "ETL"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_lab5.png`,
        github: "https://github.com/tmarsbr/DWH-Lab-5-Migracao-Local-Para-Nuvem",
        date: "2024"
    },
    {
        id: 206,
        title: "Estudo de Caso - O Que √© e Como Implementar ETL Reverso?",
        type: "Estudo de Caso",
        description: "Estudo sobre ETL Reverso (Reverse ETL) - conceitos, casos de uso e implementa√ß√£o pr√°tica.",
        technologies: ["Reverse ETL", "Data Warehouse", "Integra√ß√£o", "Analytics"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_estudo_caso.png`,
        github: "https://github.com/tmarsbr/DWH-Estudo-de-Caso-ETL-Reverso",
        date: "2024"
    },
    {
        id: 207,
        title: "Projeto 1 - Modelagem e Implementa√ß√£o de Um Data Warehouse Local",
        type: "Projeto",
        description: "Projeto completo de modelagem dimensional e implementa√ß√£o de Data Warehouse em ambiente local.",
        technologies: ["Modelagem Dimensional", "PostgreSQL", "ETL", "Data Warehouse"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_projeto1.png`,
        github: "https://github.com/tmarsbr/DWH-Projeto-1-Data-Warehouse-Local",
        date: "2024"
    },
    {
        id: 208,
        title: "Projeto 2 - Modelagem e Implementa√ß√£o de Data Warehouse na Nuvem com Amazon Redshift e Terraform",
        type: "Projeto",
        description: "Deploy de Data Warehouse na nuvem utilizando Amazon Redshift provisionado com Terraform.",
        technologies: ["Amazon Redshift", "Terraform", "AWS", "Data Warehouse"],
        course: "data-warehouse",
        courseName: "Data Warehouses e SQL",
        image: `${process.env.PUBLIC_URL}/projects/dw_projeto2.png`,
        github: "https://github.com/tmarsbr/DWH-Projeto-2-Redshift-Terraform",
        date: "2024"
    },

    // ========================================
    // CURSO 3: ETL/ELT com Airbyte e DBT
    // ========================================
    {
        id: 301,
        title: "Lab 1 - Movimenta√ß√£o de Dados Entre Bancos de Dados com Airbyte",
        type: "Laborat√≥rio",
        description: "Configura√ß√£o e execu√ß√£o de pipelines de movimenta√ß√£o de dados entre diferentes bancos de dados usando Airbyte.",
        technologies: ["Airbyte", "PostgreSQL", "MySQL", "EL"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab1.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-1-Movimentacao-Entre-Bancos",
        date: "2024"
    },
    {
        id: 302,
        title: "Lab 2 - Construindo Pipeline EL(T) com Change Data Capture (CDC)",
        type: "Laborat√≥rio",
        description: "Implementa√ß√£o de pipeline ELT com captura de mudan√ßas de dados (CDC) para sincroniza√ß√£o em tempo real.",
        technologies: ["Airbyte", "CDC", "ELT", "Debezium"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab2.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-2-Pipeline-ELT-CDC",
        date: "2024"
    },
    {
        id: 303,
        title: "Lab 3 - Carga e Sincroniza√ß√£o Incremental de Dados com Airbyte",
        type: "Laborat√≥rio",
        description: "Configura√ß√£o de cargas incrementais e sincroniza√ß√£o de dados para otimiza√ß√£o de pipelines.",
        technologies: ["Airbyte", "Incremental Sync", "ETL", "Otimiza√ß√£o"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab3.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-3-Carga-Sincronizacao-Incremental",
        date: "2024"
    },
    {
        id: 304,
        title: "Lab 4 - Plano de Execu√ß√£o e Otimiza√ß√£o de Consultas em Pipelines de Engenharia de Dados",
        type: "Laborat√≥rio",
        description: "An√°lise de planos de execu√ß√£o e t√©cnicas de otimiza√ß√£o de consultas SQL em pipelines de dados.",
        technologies: ["SQL", "Query Optimization", "EXPLAIN", "Performance"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab4.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-4-Plano-Execucao-Otimizacao-Consultas",
        date: "2024"
    },
    {
        id: 305,
        title: "Lab 5 - Modelagem de Dados Para Engenharia de Dados em Sistemas de IA",
        type: "Laborat√≥rio",
        description: "T√©cnicas de modelagem de dados otimizadas para alimentar sistemas de Intelig√™ncia Artificial.",
        technologies: ["Modelagem", "IA", "Feature Engineering", "SQL"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab5.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-5-Modelagem-Dados-IA",
        date: "2024"
    },
    {
        id: 306,
        title: "Lab 6 - Deploy e Re-Deploy do Primeiro Modelo com DBT",
        type: "Laborat√≥rio",
        description: "Primeiros passos com DBT: cria√ß√£o, deploy e re-deploy de modelos de transforma√ß√£o de dados.",
        technologies: ["DBT", "SQL", "Data Modeling", "Deploy"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab6.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-6-Deploy-Primeiro-Modelo-DBT",
        date: "2024"
    },
    {
        id: 307,
        title: "Lab 7 - Cria√ß√£o de Macros, Refatoramento e Deploy em Produ√ß√£o com DBT",
        type: "Laborat√≥rio",
        description: "Desenvolvimento de macros reutiliz√°veis, refatoramento de c√≥digo e deploy em ambiente de produ√ß√£o com DBT.",
        technologies: ["DBT", "Macros", "Jinja", "Produ√ß√£o"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab7.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-7-Macros-Refatoramento-Deploy-Producao",
        date: "2024"
    },
    {
        id: 308,
        title: "Lab 8 - Automa√ß√£o de Testes de Modelos de Dados no DBT",
        type: "Laborat√≥rio",
        description: "Implementa√ß√£o de testes automatizados para garantir qualidade e integridade dos modelos DBT.",
        technologies: ["DBT", "Testes", "Data Quality", "CI/CD"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab8.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-8-Automacao-Testes-DBT",
        date: "2024"
    },
    {
        id: 309,
        title: "Lab 9 - Analytics Engineering e Linhagem de Dados com Python, DBT, BigQuery e Looker Studio",
        type: "Laborat√≥rio",
        description: "Pipeline completo de Analytics Engineering com rastreamento de linhagem de dados usando DBT, BigQuery e visualiza√ß√£o no Looker Studio.",
        technologies: ["DBT", "BigQuery", "Looker Studio", "Python"],
        course: "airbyte-dbt",
        courseName: "ETL/ELT com Airbyte e DBT",
        image: `${process.env.PUBLIC_URL}/projects/dbt_lab9.png`,
        github: "https://github.com/tmarsbr/ED-Airbyte-DBT-SQL-Lab-9-Analytics-Engineering-Linhagem",
        date: "2024"
    },

    // ========================================
    // CURSO 4: Data Lake e Lakehouse
    // ========================================
    {
        id: 401,
        title: "Lab 1 - Plano de Custo Para Implementar Data Lakes e Data Lakehouses em Diferentes Cen√°rios",
        type: "Laborat√≥rio",
        description: "An√°lise e planejamento de custos para implementa√ß√£o de Data Lakes e Data Lakehouses em diversos cen√°rios de neg√≥cio.",
        technologies: ["Cost Analysis", "Data Lake", "Lakehouse", "Cloud"],
        course: "pipelines-airflow",
        courseName: "Data Lake e Lakehouse",
        image: `${process.env.PUBLIC_URL}/projects/lake_lab1.png`,
        github: "https://github.com/tmarsbr/DL-Lakehouse-Lab-1-Plano-Custo",
        date: "2024"
    },
    {
        id: 402,
        title: "Lab 2 - Design e Implementa√ß√£o de Data Lake Local Para Armazenamento e Processamento Distribu√≠do",
        type: "Laborat√≥rio",
        description: "Arquitetura e implementa√ß√£o de Data Lake em ambiente local com capacidade de processamento distribu√≠do.",
        technologies: ["Data Lake", "MinIO", "Spark", "Delta Lake"],
        course: "pipelines-airflow",
        courseName: "Data Lake e Lakehouse",
        image: `${process.env.PUBLIC_URL}/projects/lake_lab2.png`,
        github: "https://github.com/tmarsbr/DL-Lakehouse-Lab-2-Data-Lake-Local",
        date: "2024"
    },
    {
        id: 403,
        title: "Lab 3 - Design e Implementa√ß√£o de Data Lake na Nuvem com IaC e Terraform",
        type: "Laborat√≥rio",
        description: "Provisionamento automatizado de Data Lake em nuvem utilizando Infrastructure as Code com Terraform.",
        technologies: ["Terraform", "AWS S3", "Data Lake", "IaC"],
        course: "pipelines-airflow",
        courseName: "Data Lake e Lakehouse",
        image: `${process.env.PUBLIC_URL}/projects/lake_lab3.png`,
        github: "https://github.com/tmarsbr/DL-Lakehouse-Lab-3-Data-Lake-Nuvem-Terraform",
        date: "2024"
    },
    {
        id: 404,
        title: "Lab 4 - Linhagem, Observabilidade, Qualidade, Enriquecimento e Governan√ßa de Dados no Data Lake",
        type: "Laborat√≥rio",
        description: "Implementa√ß√£o completa de pr√°ticas de governan√ßa incluindo linhagem, observabilidade e qualidade de dados no Data Lake.",
        technologies: ["Data Governance", "Data Quality", "Lineage", "Observability"],
        course: "pipelines-airflow",
        courseName: "Data Lake e Lakehouse",
        image: `${process.env.PUBLIC_URL}/projects/lake_lab4.png`,
        github: "https://github.com/tmarsbr/DL-Lakehouse-Lab-4-Linhagem-Observabilidade-Governanca",
        date: "2024"
    },

    // ========================================
    // CURSO 5: Big Data com PySpark e Kafka
    // ========================================
    {
        id: 501,
        title: "Projeto 1 - Pipeline PySpark Para Extrair, Transformar e Carregar Arquivos JSON em Banco de Dados",
        type: "Projeto",
        description: "Pipeline ETL completo com PySpark para processamento de arquivos JSON e carga em banco de dados.",
        technologies: ["PySpark", "JSON", "ETL", "PostgreSQL"],
        course: "pyspark-kafka",
        courseName: "Big Data com PySpark e Kafka",
        image: `${process.env.PUBLIC_URL}/projects/spark_projeto1.png`,
        github: "https://github.com/tmarsbr/Spark-Kafka-Projeto-1-Pipeline-JSON-DB",
        date: "2024"
    },
    {
        id: 502,
        title: "Projeto 2 - 50 Scripts de Otimiza√ß√£o de Processamento e An√°lise de Dados em Cluster Spark",
        type: "Projeto",
        description: "Cole√ß√£o de 50 scripts otimizados para processamento e an√°lise de dados em clusters Spark.",
        technologies: ["PySpark", "Otimiza√ß√£o", "Performance", "Big Data"],
        course: "pyspark-kafka",
        courseName: "Big Data com PySpark e Kafka",
        image: `${process.env.PUBLIC_URL}/projects/spark_projeto2.png`,
        github: "https://github.com/tmarsbr/Spark-Kafka-Projeto-2-50-Scripts-Otimizacao",
        date: "2024"
    },
    {
        id: 503,
        title: "Projeto 3 - Pipeline de Limpeza e Transforma√ß√£o Para Aplica√ß√µes de IA com PySpark SQL",
        type: "Projeto",
        description: "Pipeline de prepara√ß√£o de dados para Machine Learning utilizando PySpark SQL para limpeza e transforma√ß√£o.",
        technologies: ["PySpark SQL", "Data Cleaning", "Feature Engineering", "ML"],
        course: "pyspark-kafka",
        courseName: "Big Data com PySpark e Kafka",
        image: `${process.env.PUBLIC_URL}/projects/spark_projeto3.png`,
        github: "https://github.com/tmarsbr/Spark-Kafka-Projeto-3-Pipeline-Limpeza-IA-PySparkSQL",
        date: "2024"
    },
    {
        id: 504,
        title: "Projeto 4 - Processamento e An√°lise de Dados em Tempo Real com PySpark Streaming",
        type: "Projeto",
        description: "Sistema de processamento de dados em tempo real utilizando PySpark Streaming e Apache Kafka.",
        technologies: ["PySpark Streaming", "Apache Kafka", "Real-time", "Big Data"],
        course: "pyspark-kafka",
        courseName: "Big Data com PySpark e Kafka",
        image: `${process.env.PUBLIC_URL}/projects/spark_projeto4.png`,
        github: "https://github.com/tmarsbr/Spark-Kafka-Projeto-4-Streaming-Tempo-Real",
        date: "2024"
    }
];
