// ========================================
// CONFIGURA√á√ÉO DO PORTF√ìLIO DATA & ANALYTICS
// ========================================
// Edite este arquivo para personalizar seu portf√≥lio

/**
 * Informa√ß√µes Pessoais do Profissional
 * @description Dados b√°sicos e contatos do portf√≥lio
 */
export const personalInfo = {
  name: "Tiago da Silva e Santo",
  fullName: "Tiago Da Silva E Santo",
  title: "Eng. de Dados | Data Science",
  subtitle: "Transformando dados em insights estrat√©gicos para neg√≥cios",
  location: "S√£o Paulo, SP",
  email: "tiagomars233@gmail.com",
  phone: "+55 11 97542-9994",
  linkedin: "https://www.linkedin.com/in/tiagodados",
  github: "https://github.com/tmarsbr",
  whatsapp: "https://wa.me/5511975429994",
  resume: `${process.env.PUBLIC_URL}/certificates/Curriculo_Tiago_Santo_Formatado.pdf`,
  
  // Resumo para a p√°gina inicial (1-2 frases)
  homeIntro: "Desenho e opero pipelines ETL/ELT (Airflow, dbt, Spark), modelo dados para analytics e sirvo features para ML. Foco em escalabilidade, custo e qualidade com IaC, CI/CD e DataOps na AWS.",
  
  // Descri√ß√£o expandida para a se√ß√£o Sobre
  aboutDescription: `Da Oficina para os Dados
Tudo come√ßou com barulho de torno, cheiro de √≥leo e precis√£o milim√©trica. Na usinagem, aprendi que um erro de um d√©cimo pode custar caro. Foi l√° que desenvolvi o olhar cl√≠nico, a paci√™ncia e o gosto por resolver problemas com m√©todo.

Hoje, essa precis√£o virou c√≥digo. Projeto pipelines, organizo dados brutos, crio dashboards, desenvolvo modelos preditivos e conto hist√≥rias com dados reais. Da engenharia √† an√°lise, passando pela ci√™ncia de dados, aplico o mesmo rigor t√©cnico que aprendi na mec√¢nica para transformar n√∫meros em decis√µes inteligentes.

Toler√¢ncia apertada e processo confi√°vel geram qualidade ‚Äî em a√ßo e em dados.`,


  // Avatar/Foto (deixe vazio para usar placeholder)
  avatar: `${process.env.PUBLIC_URL}/imagem/perfil.jpeg`,
};

/**
 * Categorias de Projetos
 * @description Lista de categorias principais para filtros
 */
export const PROJECT_CATEGORIES = [
  'Todos',
  'An√°lise de Dados',
  'Engenharia de Dados',
  'Ci√™ncia de Dados',
  'API & Scraping'
];

/**
 * Subcategorias por Categoria
 * @description Subfiltros espec√≠ficos para cada categoria principal
 */
export const PROJECT_SUBCATEGORIES = {
  'Engenharia de Dados': ['IaC', 'CI/CD', 'ETL/ELT', 'Cloud AWS', 'DataOps'],
  'An√°lise de Dados': ['EDA', 'Visualiza√ß√£o', 'Estat√≠stica', 'Experimenta√ß√£o'],
  'Ci√™ncia de Dados': ['ML Cl√°ssico', 'Deep Learning', 'MLOps', 'NLP'],
  'API & Scraping': ['Scraping', 'API REST', 'Integra√ß√µes'],
  'Todos': []
};

/**
 * √Årvore de Skills - Tecnologias por Subcategoria
 * @description Mapeamento de tecnologias espec√≠ficas para cada subcategoria
 * @structure { categoria: { subcategoria: [tecnologias] } }
 */
export const SKILL_TREE = {
  'Engenharia de Dados': {
    'IaC': ['Terraform'],
    'CI/CD': ['GitHub Actions', 'Docker', 'Kubernetes'],
    'ETL/ELT': ['Airbyte', 'dbt', 'Apache Spark', 'Python'],
    'Cloud AWS': ['S3', 'EMR', 'Redshift', 'Glue', 'Athena', 'DynamoDB', 'QuickSight', 'SageMaker'],
    'DataOps': ['Apache Airflow']
  },
  'Data Science': {
    'Data Science': ['EDA', 'Visualiza√ß√£o', 'Feature Engineering', 'Storytelling', 'Causalidade', 'S√©ries Temporais'],
    'Python': ['pandas', 'numpy', 'matplotlib', 'seaborn', 'plotly', 'scipy', 'polars', 'requests', 'jupyter'],
    'Machine Learning': ['scikit-learn', 'XGBoost', 'LightGBM', 'CatBoost', 'statsmodels', 'Optuna', 'OneHotEncoder', 'StandardScaler', 'Pipeline', 'Cross-Validation'],
    'SQL': ['PostgreSQL', 'MySQL', 'SQLite', 'SQL Server', 'Oracle', 'Redshift', 'Athena', 'DuckDB'],
    'Estat√≠stica': ['Descritiva', 'Infer√™ncia', 'Testes de Hip√≥tese', 'Regress√£o', 'ANOVA', 'P-valor', 'Intervalo de Confian√ßa', 'Correla√ß√£o', 'S√©ries Temporais']
  }
};

/**
 * Habilidades T√©cnicas Organizadas por Categoria
 * @description Stack tecnol√≥gico com n√≠veis de profici√™ncia (0-100)
 * @structure { categoria: [{ name, level, icon }] }
 */
export const skills = {
  "Linguagens & Bancos de Dados": [
    { name: "Python", level: 90, icon: "üêç" },
    { name: "SQL", level: 85, icon: "üóÉÔ∏è" },
    { name: "Web Scraping", level: 80, icon: "üï∑Ô∏è" },
    { name: "SQLite", level: 85, icon: "üíæ" },
    { name: "PostgreSQL", level: 80, icon: "üêò" },
    { name: "MySQL", level: 80, icon: "üóÑÔ∏è" },
    { name: "Oracle", level: 70, icon: "üìä" },
    { name: "MongoDB", level: 75, icon: "üçÉ" },
  ],
  "Machine Learning & Estat√≠stica": [
    { name: "Scikit-learn", level: 85, icon: "ü§ñ" },
    { name: "Pandas", level: 90, icon: "üêº" },
    { name: "NumPy", level: 85, icon: "üî¢" },
    { name: "SciPy", level: 80, icon: "üìà" },
    { name: "Regress√£o", level: 85, icon: "üìâ" },
    { name: "Classifica√ß√£o", level: 85, icon: "üéØ" },
    { name: "Clusteriza√ß√£o", level: 80, icon: "üìä" },
    { name: "Estat√≠stica Descritiva", level: 90, icon: "üìã" },
  ],
  "Visualiza√ß√£o & BI": [
    { name: "Matplotlib", level: 85, icon: "üìä" },
    { name: "Seaborn", level: 85, icon: "üé®" },
    { name: "Plotly", level: 80, icon: "üìà" },
    { name: "Power BI", level: 75, icon: "‚ö°" },
  ],
  "Desenvolvimento & Cloud": [
    { name: "Git/GitHub", level: 85, icon: "üîÑ" },
    { name: "Docker", level: 70, icon: "üê≥" },
    { name: "Streamlit", level: 80, icon: "üöÄ" },
    { name: "APIs Python", level: 75, icon: "üîå" },
    { name: "AWS", level: 70, icon: "‚òÅÔ∏è" },
  ],
};

/**
 * Experi√™ncias Profissionais e Educacionais
 * @description Timeline da carreira profissional e forma√ß√£o acad√™mica
 * @structure Array de objetos com: id, type, title, company, period, description, skills, icon
 */
export const experiences = [
  {
    id: 1,
    type: "work",
    title: "Auxiliar de Produ√ß√£o",
    company: "LJ Correia Equipamentos LTDA",
    period: "01/02/2018 - 07/05/2021",
    description: "Apoio √† linha de produ√ß√£o industrial com foco em organiza√ß√£o, controle de qualidade e efici√™ncia operacional.",
    skills: ["Produ√ß√£o Industrial", "Controle de Qualidade", "Organiza√ß√£o"],
    icon: "‚ö°"
  },
  {
    id: 2,
    type: "work",
    title: "Torneiro Mec√¢nico",
    company: "Cilintec Cilindros para Impress√µes LTDA",
    period: "15/07/2022 - 02/09/2023",
    description: "Usinagem de pe√ßas met√°licas de precis√£o utilizando tornos CNC e convencionais. Foco em qualidade, atendimento t√©cnico e entrega conforme especifica√ß√µes rigorosas.",
    skills: ["Torno CNC", "Leitura de Desenho T√©cnico", "Controle de Qualidade"],
    icon: "üîß"
  },
  {
    id: 3,
    type: "work",
    title: "Torneiro Mec√¢nico Aut√¥nomo",
    company: "Trabalho Aut√¥nomo",
    period: "09/2023 - Presente",
    description: "Especialista em usinagem de cadinhos de grafite para fundi√ß√£o, atendendo demandas personalizadas de clientes. Respons√°vel por todo o processo, desde o planejamento at√© a entrega final.",
    skills: ["Usinagem de Precis√£o", "Gest√£o de Projetos", "Atendimento ao Cliente"],
    icon: "‚öôÔ∏è"
  },
  {
    id: 4,
    type: "education",
    title: "Transi√ß√£o para Data & Analytics",
    company: "Pod Academy",
    period: "1/12/2023 - 8/12/2025",
    description: "A Forma√ß√£o Full Stack Dados & Analytics √© a trilha completa de Dados & Analytics, com Engenharia de Dados, Tecnologia, Computa√ß√£o em Nuvem, Neg√≥cios e Ci√™ncia de Dados do n√≠vel b√°sico at√© o especialista.",
    skills: ["Engenharia de Dados", "Computa√ß√£o em Nuvem", "Ci√™ncia de Dados", "Neg√≥cios"],
    icon: "üìä"
  }
];

/**
 * Portf√≥lio de Projetos em Data & Analytics
 * @description Projetos pr√°ticos demonstrando habilidades t√©cnicas
 * @categories "An√°lise Explorat√≥ria", "Engenharia de Dados", "Ci√™ncia de Dados", "API & Web Scraping"
 * @structure Array de objetos com dados completos do projeto
 */
export const projects = [
  {
    id: 1,
    title: "Pipeline de Integra√ß√£o - Cl√≠nicas Sanare e Reviver",
    impactPhrase: "‚ö° Projeto Real | Engenharia de Dados",
    description: "üè• Desenvolvi um pipeline ETL robusto que unificou sistemas de duas cl√≠nicas m√©dicas, migrando +10k registros com 99.9% de precis√£o e zero downtime.",
    longDescription: "Duas cl√≠nicas m√©dicas se fundiram e precisavam operar em conjunto no dia seguinte. Estruturei um pipeline orientado a objetos que tratou incompatibilidades de schemas, aplicou valida√ß√µes de qualidade e conciliou hist√≥ricos cr√≠ticos sem interrup√ß√µes. A solu√ß√£o entregou migra√ß√£o com 99.9% de acur√°cia e observabilidade ponta a ponta.",
    technologies: ["Python", "OOP", "ETL", "Data Quality", "Pandas"],
    category: "Engenharia de Dados",
    subcategories: ["ETL/ELT"],
    image: `${process.env.PUBLIC_URL}/projects/capa_integracao_sistemas_medicos.png`,
    github: "https://github.com/tmarsbr/projeto_pipeline",
    demo: "",
    metrics: "Integra√ß√£o de +10k registros, 99.9% de precis√£o na migra√ß√£o",
    featured: true,
    complexity: 5,
    date: "2024"
  },
  {
    id: 2,
    title: "Extra√ß√£o e An√°lise - Reposit√≥rios GitHub",
    impactPhrase: "üî• DataOps | Engenharia de Dados",
    description: "üêô Orquestrei coleta e an√°lise de +1000 reposit√≥rios de 15 empresas tech, entregando benchmark cont√≠nuo de stacks e produtividade.",
    longDescription: "Implementei automa√ß√µes para consumir a API do GitHub, aplicar normaliza√ß√£o de metadados e consolidar indicadores de engenharia (linguagens, cad√™ncia de commits, contributors). O pipeline gera relat√≥rios prontos para squads de tecnologia acompanharem tend√™ncias e planejar roadmap t√©cnico.",
    technologies: ["Python", "GitHub API", "Pandas", "Requests", "JSON"],
    category: "Engenharia de Dados",
    subcategories: ["DataOps"],
    image: `${process.env.PUBLIC_URL}/projects/capa_github_analysis.png`,
    github: "https://github.com/tmarsbr/Projeto_api",
    demo: "",
    metrics: "Coleta cont√≠nua de +1000 reposit√≥rios, 15 empresas monitoradas",
    featured: false,
    complexity: 3,
    date: "2024"
  },
  {
    id: 3,
    title: "Pipeline Python - MongoDB - MySQL",
    impactPhrase: "‚≠ê Destaque | Engenharia de Dados",
    description: "üîÑ Pipeline completo para e-commerce integrando MongoDB e MySQL, reduzindo em 70% o tempo de an√°lise da equipe de BI.",
    longDescription: "Projetei um pipeline modular que captura dados semiestruturados no MongoDB, aplica regras de transforma√ß√£o com Python e povoa camadas relacionais em MySQL prontas para o BI. Logs, monitoramento de SLA e testes autom√°ticos garantem confiabilidade operacional.",
    technologies: ["Python", "MongoDB", "MySQL", "ETL", "PyMongo"],
    category: "Engenharia de Dados",
    subcategories: ["ETL/ELT"],
    image: `${process.env.PUBLIC_URL}/projects/capa_pipeline_mongo_mysql.png`,
    github: "https://github.com/tmarsbr/pipeline-python-mongo-mysql",
    demo: "",
    metrics: "Redu√ß√£o de 70% no tempo de an√°lise da equipe de BI",
    featured: true,
    complexity: 4,
    date: "2024"
  },
  {
    id: 4,
    title: "Automatizando Infraestrutura de Processamento de Dados com AWS EMR e Apache Flink",
    impactPhrase: "‚òÅÔ∏è Streaming | Engenharia de Dados",
    description: "‚öôÔ∏è Estruturei pipeline distribu√≠do em AWS EMR com Apache Flink para processar streams em tempo real com baixa lat√™ncia.",
    longDescription: "Desenhei arquitetura em AWS EMR executando aplica√ß√µes Flink para ingerir eventos de alto volume, aplicar agrega√ß√µes em janela e persistir resultados em data lake otimizado. A solu√ß√£o suporta autoscaling, checkpoints tolerantes a falha e reduz a lat√™ncia anal√≠tica para segundos.",
    technologies: ["AWS EMR", "Apache Flink", "Kinesis", "S3", "Terraform"],
    category: "Engenharia de Dados",
    subcategories: ["Cloud AWS", "DataOps", "IaC"],
    image: `${process.env.PUBLIC_URL}/projects/capa_streaming_kafka.png`,
    github: "",
    demo: "",
    metrics: "Processamento cont√≠nuo com SLA sub-segundo e escalabilidade el√°stica",
    featured: true,
    complexity: 5,
    date: "2024"
  },
  {
    id: 5,
    title: "Pipeline PySpark para Extrair, Transformar e Carregar Arquivos JSON",
    impactPhrase: "üíæ Batch ETL | Engenharia de Dados",
    description: "üß± Desenvolvi pipeline PySpark que padroniza JSON brutos e carrega dados confi√°veis em banco relacional.",
    longDescription: "Implementei job PySpark que l√™ lotes de arquivos JSON, aplica schema enforcement, trata anomalias e entrega datasets normalizados em banco SQL. Controles de qualidade e particionamento otimizam tempo de carga e consultas anal√≠ticas.",
    technologies: ["PySpark", "Python", "SQL", "Airflow"],
    category: "Engenharia de Dados",
    subcategories: ["ETL/ELT"],
    image: `${process.env.PUBLIC_URL}/projects/capa_automacao_etl.png`,
    github: "",
    demo: "",
    metrics: "Carga di√°ria de JSON com 100% de consist√™ncia referencial",
    featured: false,
    complexity: 4,
    date: "2024"
  },
  {
    id: 6,
    title: "Pipeline de Limpeza e Transforma√ß√£o para Aplica√ß√µes de IA com PySpark SQL",
    impactPhrase: "ü§ñ Data Quality | Engenharia de Dados",
    description: "üßπ Estruturei camada confi√°vel para modelos de IA usando PySpark SQL, padronizando features cr√≠ticas.",
    longDescription: "Criei camadas bronze, silver e gold em PySpark SQL, com regras de normaliza√ß√£o, deduplica√ß√£o e enriquecimento de atributos. A esteira garante datasets prontos para ML com m√©tricas de qualidade rastreadas via dashboards observ√°veis.",
    technologies: ["PySpark SQL", "Delta Lake", "Great Expectations", "Databricks"],
    category: "Engenharia de Dados",
    subcategories: ["DataOps"],
    image: `${process.env.PUBLIC_URL}/projects/capa_data_lake.png`,
    github: "",
    demo: "",
    metrics: "Melhoria de 35% na acur√°cia dos modelos ap√≥s saneamento",
    featured: false,
    complexity: 4,
    date: "2024"
  },
  {
    id: 7,
    title: "Automa√ß√£o de Testes de Modelos de Dados no dbt",
    impactPhrase: "‚úÖ Qualidade | Engenharia de Dados",
    description: "üß™ Automatizei testes no dbt garantindo integridade e versionamento de modelos anal√≠ticos.",
    longDescription: "Configurei rotina CI/CD com dbt, parametrizando testes de schema, dados e rela√ß√µes. Integra√ß√£o com GitHub Actions entrega valida√ß√µes a cada deploy, alertas proativos e documenta√ß√£o atualizada dos modelos.",
    technologies: ["dbt", "GitHub Actions", "SQL", "CI/CD"],
    category: "Engenharia de Dados",
    subcategories: ["CI/CD", "DataOps"],
    image: `${process.env.PUBLIC_URL}/projects/capa_docker_deploy.png`,
    github: "",
    demo: "",
    metrics: "Cobertura de testes 100% automatizada em pipelines versionados",
    featured: false,
    complexity: 3,
    date: "2024"
  },
  {
    id: 8,
    title: "Movimenta√ß√£o de Dados Entre Bancos de Dados com Airbyte",
    impactPhrase: "üîå Integra√ß√£o | Engenharia de Dados",
    description: "üåê Configurei Airbyte para sincronizar bancos relacionais e alimentar pipelines ETL escal√°veis.",
    longDescription: "Modelei conectores no Airbyte para mover dados entre fontes heterog√™neas, com logging, recupera√ß√£o autom√°tica e versionamento das configura√ß√µes. A solu√ß√£o encurta setup de integra√ß√µes e suporta replica√ß√£o incremental confi√°vel.",
    technologies: ["Airbyte", "PostgreSQL", "MySQL", "Docker"],
    category: "Engenharia de Dados",
    subcategories: ["ETL/ELT"],
    image: `${process.env.PUBLIC_URL}/projects/capa_automacao_bots.png`,
    github: "",
    demo: "",
    metrics: "Replica√ß√£o incremental agendada em minutos com alertas autom√°ticos",
    featured: false,
    complexity: 3,
    date: "2024"
  }
];

/**
 * Certifica√ß√µes e Forma√ß√µes Acad√™micas
 * @description Certificados obtidos em cursos e forma√ß√µes
 * @structure Array com dados dos certificados e links para PDFs
 */
export const certificates = [
  {
    id: 1,
    title: "Nivelamento em Matem√°tica, Estat√≠stica e Programa√ß√£o para Big Data & Analytics",
    institution: "PoD Academy",
    year: "2024",
    duration: "120h",
    image: `${process.env.PUBLIC_URL}/certificates/1.png`,
    pdf: `${process.env.PUBLIC_URL}/certificates/certificado-2026662A6157507713239070.pdf`,
    skills: ["Matem√°tica", "Estat√≠stica", "Programa√ß√£o", "Big Data"]
  },
  {
    id: 2,
    title: "Ci√™ncias Aplicadas: Matem√°tica e Estat√≠stica",
    institution: "PoD Academy",
    year: "2025",
    duration: "80h",
    image: `${process.env.PUBLIC_URL}/certificates/4.png`,
    pdf: `${process.env.PUBLIC_URL}/certificates/certificado-2427912AD2AF41E914203880.pdf`,
    skills: ["Matem√°tica Aplicada", "Estat√≠stica Aplicada", "Dados"]
  },
  {
    id: 3,
    title: "Forma√ß√£o em An√°lise de Dados",
    institution: "PoD Academy",
    year: "2024",
    duration: "100h",
    image: `${process.env.PUBLIC_URL}/certificates/3.png`,
    pdf: `${process.env.PUBLIC_URL}/certificates/certificado-2184196A1D520FC214203880.pdf`,
    skills: ["An√°lise de Dados", "CRISP-DM", "Estat√≠stica", "Visualiza√ß√£o"]
  },
  {
    id: 4,
    title: "Cloud Computing",
    institution: "PoD Academy",
    year: "2024",
    duration: "60h",
    image: `${process.env.PUBLIC_URL}/certificates/2.png`,
    pdf: `${process.env.PUBLIC_URL}/certificates/certificado-2181848AF6E35A5F13239070.pdf`,
    skills: ["Cloud Computing", "AWS", "Azure", "GCP"]
  },
  {
    id: 5,
    title: "An√°lise de Neg√≥cios",
    institution: "Forma√ß√£o em Ci√™ncia de Dados",
    year: "2024",
    duration: "40h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_analise_negocios.png`,
    pdf: "",
    skills: ["An√°lise de Neg√≥cios", "KPIs", "M√©tricas", "Estrat√©gia"]
  },
  {
    id: 6,
    title: "Regress√£o Linear - Python",
    institution: "Data Viking",
    year: "2024",
    duration: "20h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_regressao_linear.png`,
    pdf: "",
    skills: ["Python", "Regress√£o Linear", "Machine Learning", "Estat√≠stica"]
  },
  {
    id: 7,
    title: "Floresta Aleat√≥ria (Random Forest)",
    institution: "Data Viking",
    year: "2024",
    duration: "25h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_random_forest.png`,
    pdf: "",
    skills: ["Random Forest", "Machine Learning", "Python", "Algoritmos"]
  },
  {
    id: 8,
    title: "Regress√£o Log√≠stica - Python",
    institution: "Data Viking",
    year: "2024",
    duration: "22h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_regressao_logistica.png`,
    pdf: "",
    skills: ["Regress√£o Log√≠stica", "Python", "Machine Learning", "Classifica√ß√£o"]
  },
  {
    id: 9,
    title: "SQL com Python",
    institution: "Data Viking",
    year: "2024",
    duration: "30h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_sql_python.png`,
    pdf: "",
    skills: ["SQL", "Python", "Banco de Dados", "SQLite"]
  },
  {
    id: 10,
    title: "Forma√ß√£o Python Impressionador",
    institution: "Hashtag Treinamentos",
    year: "2024",
    duration: "50h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_python_impressionador.png`,
    pdf: "",
    skills: ["Python", "Automa√ß√£o", "Data Science", "Pandas"]
  },
  {
    id: 11,
    title: "Forma√ß√£o SQL Impressionador",
    institution: "Hashtag Treinamentos",
    year: "2024",
    duration: "45h",
    image: `${process.env.PUBLIC_URL}/certificates/capa_certificado_sql_impressionador.png`,
    pdf: "",
    skills: ["SQL", "Banco de Dados", "Consultas Avan√ßadas", "Performance"]
  },
  {
    id: 12,
    title: "Git e GitHub Essencial",
    institution: "DIO",
    year: "2023",
    duration: "15h",
    image: "",
    pdf: "",
    skills: ["Git", "GitHub", "Controle de Vers√£o", "Colabora√ß√£o"]
  }
];

/**
 * Configura√ß√µes de Tema e Estilo
 * @description Paleta de cores, tipografia e espa√ßamentos para modo claro/escuro
 * @includes cores, fontes, espa√ßamentos, bordas e transi√ß√µes
 */
export const themeConfig = {
  // Cores principais - refinadas para melhor contraste e harmonia
  light: {
    primaryColor: "#1565c0", // Azul mais vibrante e profissional
    secondaryColor: "#d32f2f", // Vermelho mais equilibrado
    accentColor: "#00897b", // Verde-azulado sofisticado
    backgroundColor: "#fafafa",
    paperColor: "#ffffff",
    alternateBackground: "#f5f7fa", // Off-white para se√ß√µes alternadas
    textPrimary: "#2c3e50", // Texto mais escuro para melhor contraste
    textSecondary: "#64748b", // Cinza moderno
    dividerColor: "#e2e8f0",
    shadow: "0 4px 20px rgba(0, 0, 0, 0.08)",
    hoverShadow: "0 12px 40px rgba(0, 0, 0, 0.15)"
  },
  dark: {
    primaryColor: "#64b5f6", // Azul suave para fundo escuro
    secondaryColor: "#ef5350", // Vermelho suave
    accentColor: "#4db6ac", // Verde-azulado suave
    backgroundColor: "#0f172a", // Azul muito escuro
    paperColor: "#1e293b", // Cinza-azul escuro para cards
    alternateBackground: "#1a202c", // Cinza escuro para se√ß√µes alternadas
    textPrimary: "#f1f5f9", // Branco quase puro
    textSecondary: "#94a3b8", // Cinza claro
    dividerColor: "#334155",
    shadow: "0 4px 20px rgba(0, 0, 0, 0.3)",
    hoverShadow: "0 12px 40px rgba(0, 0, 0, 0.5)"
  },
  
  // Tipografia aprimorada com Google Fonts
  fontFamily: "'Inter', 'Roboto', 'Segoe UI', 'Helvetica Neue', sans-serif",
  fontSize: {
    xs: "0.75rem",
    small: "0.875rem", 
    medium: "1rem",
    large: "1.25rem",
    xlarge: "2rem",
    xxlarge: "3rem",
    xxxlarge: "3.75rem"
  },
  fontWeight: {
    light: 300,
    regular: 400,
    medium: 500,
    semibold: 600,
    bold: 700
  },
  
  // Espa√ßamentos seguindo o padr√£o 8px
  spacing: {
    xs: "4px",
    sm: "8px",
    md: "16px",
    lg: "24px",
    xl: "32px",
    xxl: "48px",
    xxxl: "64px"
  },
  
  // Border radius padronizado
  borderRadius: {
    small: "6px",
    medium: "12px",
    large: "16px",
    xl: "24px",
    round: "50%"
  },
  
  // Anima√ß√µes e transi√ß√µes
  transitions: {
    fast: "0.15s ease-out",
    normal: "0.3s ease-in-out", 
    slow: "0.5s ease-in-out"
  }
};

/**
 * Configura√ß√µes de SEO (Search Engine Optimization)
 * @description Metadados para otimiza√ß√£o em motores de busca
 * @includes title, description, keywords, Open Graph, Twitter Cards
 */
export const seoConfig = {
  title: "Tiago Silva ‚Äî Eng. de Dados | Data Science",
  description: "Engenharia de Dados e Data Science: ETL/ELT (Airflow, dbt, Spark), analytics e features para ML. IaC, CI/CD e DataOps na AWS.",
  keywords: "engenharia de dados, data engineering, data science, analytics, python, machine learning, sql, aws, airflow, dbt, spark, tiago silva, portf√≥lio",
  author: "Tiago Silva",
  url: "https://tmarsbr.github.io/portifolio-data-analytics", // URL do GitHub Pages
  image: `${process.env.PUBLIC_URL}/og-image.jpg`, // Adicione uma imagem de preview
  
  // Open Graph
  ogTitle: "Tiago Silva ‚Äî Eng. de Dados | Data Science",
  ogDescription: "ETL/ELT (Airflow, dbt, Spark), modelagem para analytics e features de ML. IaC, CI/CD e DataOps na AWS.",
  twitterCard: "summary_large_image",
  twitterCreator: "@tiagodados" // Se tiver Twitter
};

/**
 * Configura√ß√µes do Google Analytics
 * @description Tracking e m√©tricas de acesso (opcional)
 */
export const analyticsConfig = {
  trackingId: process.env.REACT_APP_TRACKING_ID || "",
  enabled: process.env.NODE_ENV === "production"
};

/**
 * Configura√ß√£o Principal do Portf√≥lio
 * @description Exporta√ß√£o unificada de todas as configura√ß√µes
 * @exports Objeto contendo todas as se√ß√µes do portf√≥lio
 */
const portfolioConfig = {
  personalInfo,
  skills,
  experiences,
  projects,
  certificates,
  themeConfig,
  seoConfig,
  analyticsConfig
};

export default portfolioConfig;
